{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbff8f59",
   "metadata": {},
   "source": [
    "# Ad3_Gabriela_Castro\n",
    "## Ejercicio Python para lograr un scraping de una web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87449404",
   "metadata": {},
   "source": [
    "A Continuación trabajaremos en **la actividad 3**, en la cual elaboraremos un ejercicio *Scraping* Web a través del lenguaje de programación Python en una librería de la plataforma Jupyter en formato .ipymb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802c865",
   "metadata": {},
   "source": [
    "Para iniciar a trabajar debemos tener el código fuente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1816ac9",
   "metadata": {},
   "source": [
    "### Código fuente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce995a1c",
   "metadata": {},
   "source": [
    "```\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "\n",
    "resultados = []\n",
    "\n",
    "req = requests.get(\"https://resultados.elpais.com\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    " \n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "tags = soup.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req2 = requests.get(\"https://elpais.com/internacional\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup2 = BeautifulSoup(req2.text, 'html.parser')\n",
    "\n",
    "tags = soup2.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req3 = requests.get(\"https://elpais.com/opinion\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup3 = BeautifulSoup(req3.text, 'html.parser')\n",
    "\n",
    "tags = soup3.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req4 = requests.get(\"https://elpais.com/espana/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup4 = BeautifulSoup(req4.text, 'html.parser')\n",
    "\n",
    "tags = soup4.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req5 = requests.get(\"https://elpais.com/economia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup5 = BeautifulSoup(req5.text, 'html.parser')\n",
    "\n",
    "tags = soup5.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req6 = requests.get(\"https://elpais.com/sociedad/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup6 = BeautifulSoup(req6.text, 'html.parser')\n",
    "\n",
    "tags = soup6.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req7 = requests.get(\"https://elpais.com/educacion/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup7 = BeautifulSoup(req7.text, 'html.parser')\n",
    "\n",
    "tags = soup7.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req8 = requests.get(\"https://elpais.com/clima-y-medio-ambiente/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup8 = BeautifulSoup(req8.text, 'html.parser')\n",
    "\n",
    "tags = soup8.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req9 = requests.get(\"https://elpais.com/ciencia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup9 = BeautifulSoup(req9.text, 'html.parser')\n",
    "\n",
    "tags = soup9.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req10 = requests.get(\"https://elpais.com/cultura/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup10 = BeautifulSoup(req10.text, 'html.parser')\n",
    "\n",
    "tags = soup10.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req11 = requests.get(\"https://elpais.com/babelia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup11 = BeautifulSoup(req11.text, 'html.parser')\n",
    "\n",
    "tags = soup11.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req12 = requests.get(\"https://elpais.com/deportes/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup12 = BeautifulSoup(req12.text, 'html.parser')\n",
    "\n",
    "tags = soup12.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req13 = requests.get(\"https://elpais.com/tecnologia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup13 = BeautifulSoup(req13.text, 'html.parser')\n",
    "\n",
    "tags = soup13.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req14 = requests.get(\"https://elpais.com/tecnologia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup14 = BeautifulSoup(req14.text, 'html.parser')\n",
    "\n",
    "tags = soup14.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req15 = requests.get(\"https://elpais.com/gente/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup15 = BeautifulSoup(req15.text, 'html.parser')\n",
    "\n",
    "tags = soup15.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req16 = requests.get(\"https://elpais.com/television/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup16 = BeautifulSoup(req16.text, 'html.parser')\n",
    "\n",
    "tags = soup16.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req17 = requests.get(\"https://elpais.com/eps/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup17 = BeautifulSoup(req17.text, 'html.parser')\n",
    "\n",
    "tags = soup17.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "\n",
    "os.system(\"clear\")\n",
    "\n",
    "print(colored(\"A continuación se muestran los titulares de las páginas principales del diario El País que contienen las siguientes palabras:\", 'blue', attrs=['bold']))\n",
    "print(colored(\"Feminismo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"feminismo\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Igualdad\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"igualdad\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Mujeres\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"mujeres\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Mujer\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"mujer\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Brecha salarial\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"brecha salarial\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Machismo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"machismo\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Violencia\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"violencia\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Maltrato\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"maltrato\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Homicidio\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"homicidio\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Género\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"género\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Asesinato\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"asesinato\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Sexo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"sexo\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802b145",
   "metadata": {},
   "source": [
    "Luego Tenemos que instalar las Librerías para realizar el web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d22529f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\gabri\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\gabri\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: termcolor in c:\\users\\gabri\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests bs4 pandas termcolor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e90d947",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af49ef7",
   "metadata": {},
   "source": [
    "#### Librerías internas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea099a",
   "metadata": {},
   "source": [
    "- `csv`: de *comma separated values* o Valores Separados por Comas es el formato muy habitual importación y exportación de hojas de cálculo y bases de datos.\n",
    "- `re`:Este módulo proporciona operaciones de coincidencia de expresiones regulares similares a las encontradas en Perl.\n",
    "- `time`:Este módulo proporciona varias funciones relacionadas con el tiempo. Para la funcionalidad relacionada, consulte también los módulos datetime y calendar.\n",
    "- `os`:Este módulo provee una manera versátil de usar funcionalidades dependientes del sistema operativo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01871d4",
   "metadata": {},
   "source": [
    "#### Librerías externas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffc954",
   "metadata": {},
   "source": [
    "- Termcolor: Es una biblioteca que sirve para imprimir mensajes de colores en el terminal.\n",
    "- bs4: Beautiful Soup (bs4) es una biblioteca de la cual podemos obtener datos en formato HTML y XML\n",
    "- requests: Se usa para hacer solicitudes y peticiones a la página de la que extraeremos datos.\n",
    "- pandas: Es una herramienta de análisis de datos de código, de lectura rápida en el lenguaje de programación de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78962d",
   "metadata": {},
   "source": [
    "Luego Importamos las librerias para que los siguentes comandos puedan trabajar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c545a",
   "metadata": {},
   "source": [
    "### Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ca986",
   "metadata": {},
   "source": [
    "Creamos una variable llamada **resultado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18b9a8",
   "metadata": {},
   "source": [
    "Para saber qué tipo de variables usamos la función *type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1fab203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa6aa4",
   "metadata": {},
   "source": [
    "El paso siguiente solicitar el acceso de los datos del portal Web para imprimir los titulares **El PAÍS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f025e24",
   "metadata": {},
   "source": [
    "### Solicitud de acceso "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1ba04",
   "metadata": {},
   "source": [
    "req = requests.get(\"https://resultados.elpais.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cd96a",
   "metadata": {},
   "source": [
    "**get** significa dame la página de **El País** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc165c",
   "metadata": {},
   "source": [
    "Despues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932782e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686b194",
   "metadata": {},
   "source": [
    "Lo que nos dara como resultado **requests.models.Response** que representa la respuesta de **req**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c124433",
   "metadata": {},
   "source": [
    "Para solo usar valores iguala a 200 se debe usar el elemnto **if** para que nos muestre solo los estados satisfactorios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9facb0c",
   "metadata": {},
   "source": [
    "### Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce8abc",
   "metadata": {},
   "source": [
    "Se agrega la variable Beautiful para guardar los *Tags* para que se añadan en lista los titulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc7b47",
   "metadata": {},
   "source": [
    "Añadimos la variable para encontrar las **h2** através de un **for** y se impriman las etiquetas y sus textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8eaa6c",
   "metadata": {},
   "source": [
    "Luego se crea una variable **soup** donde se encuentra **BeautifulSoup(req.text, 'html.parser')**, lo cual toma el texto, lo analiza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84fe90b",
   "metadata": {},
   "source": [
    "El próximo paso es crear una variable llamada **tags** con la que buscamos todos los **h2** (titulares de las noticias) partir del texto analizado por **BeautifulSoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acbe79fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Mundial, en vivo\n",
      "Universo Mundial\n",
      "El calendario a seguir desde América\n",
      "¿Quién va a ganar? Simulador y pronóstico de cada selección \n",
      "La ‘newsletter’\n",
      "Las protestas se extienden en China contra la política de covid cero\n",
      "La gestión del frío enfrenta a Zelenski y al alcalde de Kiev\n",
      "La vida bajo los bombardeos rusos\n",
      "Así se vive en un refugio invernal durante la guerra\n",
      "Pobreza en el Olimpo académico de EE UU: la huelga que cimbra a la Universidad de California \n",
      "El caótico primer mes de Elon Musk en Twitter\n",
      "‘Argentina, 1985’, un debate nacional entre la ficción y la memoria\n",
      "Alemania rescata un empate contra España sobre el final del partido\n",
      "Un empate socialdemócrata\n",
      "Datos y gráficos | Alemania explota un error de España para empatar un partido equilibrado\n",
      "Croacia da vuelta el partido y elimina a Canadá (4-1)\n",
      "Marruecos da un batacazo a Bélgica sobre el final (0-2)\n",
      "Costa Rica se redime ante un Japón sin puntería (0-1)\n",
      "Madrid, la nueva Miami: así se han hecho con la capital española los ricos latinoamericanos\n",
      "López Obrador saca músculo en las calles con una manifestación masiva en México\n",
      "El Bosque, el pueblo mexicano que se tragó el mar\n",
      "Argentina contra la impunidad de los feminicidios\n",
      "Neofascistas, nacionalpopulistas, tecnosoberanistas. ¿Cómo llamamos a las nuevas derechas radicales? \n",
      "Las abuelas que han viralizado el arte de elaborar la pasta italiana\n",
      "Pepa Bueno: “Las páginas de EL PAÍS tienen que ser el lugar donde los diferentes se encuentren”\n",
      "Videoanálisis | La FIL mastodóntica y popular está de vuelta\n",
      "La FIL de Guadalajara pone una vela al libro y otra al balón\n",
      "Concepción Company: “De todos los mexicanismos me quedo con apapachar”\n",
      "El acoso invernal de Putin \n",
      "Por el bien de todos\n",
      "Otra forma de violencia política\n",
      "Yo te vi, papá, emocionarte con Messi\n",
      "Ideas de regalos para el jardinero\n",
      "Guía de regalos para el ‘foodie’\n",
      "Bolsonaro reaparece en una ceremonia militar tras batallar su derrota desde la trastienda\n",
      "El sueño hecho realidad del refugiado sirio del selfi con Merkel\n",
      "Crónica del asesinato de una niña en la Francia rural\n",
      "La violencia verbal de Vox desborda el Congreso español\n",
      "\n",
      "El negocio de las chicas imagen en las discotecas: “La misión es sonreír y que los hombres beban más”\n",
      "Las guatemaltecas que estudian ingeniería para llevar luz a sus comunidades\n",
      "Impresiones 3D y Telegram: el premiado proyecto de estudiantes colombianos para potabilizar agua\n",
      "La ‘ciudad esponja’: diez soluciones para resolver el problema del agua en México\n",
      "Cómic y energía nuclear: el superventas francés que sacude el debate sobre el cambio climático\n",
      "En la biblioteca de Almudena Grandes\n",
      "Otras mujeres\n",
      "Adiós a Ellen Pompeo, la funcionaria de la tele\n",
      "¿Selfie sí o selfie no en Art Basel?\n",
      "De las galerías a las calles: así se hizo importante Miami para el arte del mundo\n",
      "La bestial tensión sexual entre Bruce Willis y Cybill Shepherd en ‘Luz de luna’, la serie en la que la actriz tuvo mucho que decir\n",
      "Confesiones de la mujer que lleva 40 años decidiendo quién será el nuevo James Bond\n",
      "Alessandro Michele, crónica de una salida anunciada\n",
      "Leonor Lavado: “Somos como hablamos: la voz es nuestro ADN psicológico”\n",
      "De la carnicería de su padre en España a la estrella Michelin en Chicago\n",
      "Macondo Inundado: el pueblo donde nunca deja de llover \n",
      "Dormir en una caja a 200 euros la noche para asistir al Mundial de Qatar\n",
      "Retrato de Pablo Milanés a través de sus 10 canciones más decisivas\n",
      "De Honduras a Ucrania: cuando un niño crece bajo las bombas\n",
      "Qatar 2022, el único mundial donde es posible ver dos partidos en un mismo día\n",
      "¿Qué estrella tuvo el mejor debut en el Mundial? El ‘tier list’ de Jesús Gallego, Bruno Alemany y Aritz Gabilondo\n",
      "Enredados en el Mundial | Los jugadores iraníes vuelven a cantar el himno y ha nacido una estrella en EE UU\n",
      "Al menos 500 alpacas mueren por una ola de frío en Perú\n",
      "Los partidarios de Bolsonaro utilizan sus móviles para pedir un golpe “extraterrestre” \n",
      "Cuatro carceleros dan un brutal paliza a un hombre negro en Georgia\n",
      "Protests spread across China as anger builds over Xi Jinping’s zero-Covid policy \n",
      "War in Ukraine: The battle to survive sub-zero temperatures \n",
      "The story of a crypto scammer that ended in suicide\n",
      "To boost oil supplies, US looks to lift sanctions on Venezuela\n",
      "Americanas: Reportajes y noticias sobre feminismo e historias con enfoque de género de la región\n",
      "Toda la actualidad científica en el boletín de Materia\n",
      "Letras Americanas: la actualidad literaria de un continente vista por el escritor Emiliano Monge\n",
      "Ideas: reportajes y entrevistas para entender el mundo\n",
      "El Kremlin silencia el dolor de las mujeres rusas que critican la guerra de Ucrania \n",
      "El primer ministro de Rumania: “Necesitamos un esfuerzo común en la OTAN para defender cada centímetro de territorio frente a Rusia”  \n",
      "La justicia investiga si el Gobierno de Macron favoreció a consultoras privadas en las dos últimas campañas presidenciales en Francia\n",
      "Aquí puede buscar si ha sido engañado por la estafa internacional de las criptomonedas\n",
      "El secreto de la pirámide\n",
      "El futuro de las compras: más redes sociales, pago a plazos y vuelta de la tienda física\n",
      " El Papa detecta fallos en Caritas Internationalis y cesa a sus responsables \n",
      "La Iglesia italiana da por primera vez cifras de los abusos cometidos por el clero\n",
      "El Senado de EE UU da un paso clave para blindar el matrimonio homosexual frente al Supremo\n",
      "Muere Hans Magnus Enzensberger, gran intelectual alemán del siglo XX\n",
      "‘Close’, una mirada conmovedora a la fragilidad de la preadolescencia\n",
      "La gran retrospectiva de Vermeer en Ámsterdam aviva la polémica sobre la autoría de ‘Muchacha con flauta’\n",
      "Vivir con un trastorno alimentario: “Me di cuenta cuando me miré al espejo y vi la muerte”\n",
      "Josefa Ros Velasco, filósofa: “Si alguien se aburre suele darse a la botella, cuando le pasa a un país suele darse una revuelta”\n",
      "La insólita historia de la mujer que descubrió el primer antibiótico español\n",
      "Canadá conquista su primera Davis a lomos de Aliassime\n",
      "La selección femenina de baloncesto se clasifica para el próximo Eurobasket\n",
      "La trituradora del Barcelona no tiene piedad con el Atlético (1-6)\n",
      "Operación ‘OS35’: cómo rescatar un gigante de 40.288 toneladas varado a la sombra de Gibraltar\n",
      "¿Podré matar a una rata que entre en mi casa? Claves de la reforma del Código Penal para castigar más el maltrato animal\n",
      "La izquierda retira por sorpresa y a última hora la propuesta para abolir los toros en Francia \n",
      "Mastodon: qué es y cómo funciona la red social en la que los usuarios deciden qué está permitido\n",
      "Así serán las nuevas marcas de verificación en Twitter: azul, oro y gris\n",
      "Gafas con funciones de un móvil, ‘Photoshop’ instantáneo y otros inminentes avances gracias a los nuevos chips\n",
      "Sánchez pide a la patronal que negocie con los sindicatos un acuerdo salarial\n",
      "El pasado franquista pervive en Santa Cruz de Tenerife\n",
      "La federación de la España Vaciada busca implantarse en todo el país \n",
      "El ‘bon vivant’ acorralado de la FIFA que grabó a sus amigos\n",
      "¿Qué ocurre tras la edad de oro de la televisión? El mismo oro, aunque enterrado bajo una oferta masiva\n",
      "‘This England’, por Carlos Boyero\n",
      "Windsor desvela su decoración navideña en las primeras festividades sin Isabel II y con Carlos III como rey\n",
      "Camila y los 1.000 osos Paddington: la reina entrega a una ONG infantil los peluches en homenaje a Isabel II\n",
      "Stallone vs. Schwarzenegger, la “competición” eterna: “Éramos antagonistas. Soñaba con pegarle y él con pegarme a mí”\n",
      "El misterio de Manuel Carrasco: cómo salir de una barriada de pescadores y acabar siendo un cantante que llena estadios\n",
      "Los guardianes de la ensaladilla rusa, la tapa popular que subió a los altares ‘gourmet’ \n",
      "Erri De Luca, escritor: “Construir una vida es más difícil que contarla”\n",
      "Descansar está mal visto: el arte perdido del reposo\n",
      "Perdidos en el laberinto del paro\n",
      "Su vecino lo timaba con la calefacción central\n",
      "En la cuneta del sueño americano\n",
      "Descuidos de seleccionador: los lectores agregan libros de fútbol que no entraron en la lista\n",
      "Mi combate contra la ablación y el VIH en Senegal\n",
      "Masacre en Melilla: la peligrosa decisión de socialistas y populares\n",
      "Oyambre, Son Bou y otras nueve playas españolas para un baño de historia\n",
      "Cómo actuar ante el caos de los aeropuertos: qué hacer frente a retrasos y cancelaciones de un vuelo\n",
      "Samantha Hudson: “Me va bien económicamante, pero no soy Paula Echevarría. Nunca seré normativa”\n",
      "Alaska: “No entiendo la cultura de la cancelación”\n",
      "¿Es buena idea masturbarse antes de salir? Las verdades y mentiras de la relajación posorgasmo\n",
      "El dilema Kit Connor: ¿debe conocerse la sexualidad de un actor para interpretar un papel gay?\n",
      "Vender carne... y un estilo de vida: así son las nuevas hamburgueserías\n",
      "¿Cuál es la mejor receta de puré de patatas?\n",
      "Las nuevas jubilaciones: más retiros parciales, casi a los 65 años y cobrando 1.258 euros\n",
      "“Me rompí por dentro y hasta hoy”: desgarrador testimonio de una mujer a la que nadie creyó mientras era víctima de acoso\n",
      "Macarena Olona sorprende a todos al publicar este mensaje sobre Begoña Gómez\n",
      "Le van a llover los palos: la cantada de Courtois que mete en un lío gordo a Bélgica\n",
      "Ocho mil millones de cursis\n",
      "Las 10 mejores películas y sagas posapocalípticas\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "tags = soup.findAll(\"h2\")\n",
    " \n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3f291",
   "metadata": {},
   "source": [
    "Este proceso se repetirá en cada sección del periódico digital, creando un bucle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2ad48",
   "metadata": {},
   "source": [
    "Luego crearemos variables con las distintas url de cada sección del periódico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719dc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "req4 = requests.get(\"https://elpais.com/espana/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup4 = BeautifulSoup(req4.text, 'html.parser')\n",
    "\n",
    "tags = soup4.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "req2 = requests.get(\"https://elpais.com/internacional\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup2 = BeautifulSoup(req2.text, 'html.parser')\n",
    "\n",
    "tags = soup2.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "req5 = requests.get(\"https://elpais.com/economia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup5 = BeautifulSoup(req5.text, 'html.parser')\n",
    "\n",
    "tags = soup5.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1645473",
   "metadata": {},
   "outputs": [],
   "source": [
    "req6 = requests.get(\"https://elpais.com/sociedad/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup6 = BeautifulSoup(req6.text, 'html.parser')\n",
    "\n",
    "tags = soup6.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "req7 = requests.get(\"https://elpais.com/educacion/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup7 = BeautifulSoup(req7.text, 'html.parser')\n",
    "\n",
    "tags = soup7.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16db28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "req8 = requests.get(\"https://elpais.com/clima-y-medio-ambiente/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup8 = BeautifulSoup(req8.text, 'html.parser')\n",
    "\n",
    "tags = soup8.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "req9 = requests.get(\"https://elpais.com/ciencia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup9 = BeautifulSoup(req9.text, 'html.parser')\n",
    "\n",
    "tags = soup9.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d68d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "req10 = requests.get(\"https://elpais.com/cultura/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup10 = BeautifulSoup(req10.text, 'html.parser')\n",
    "\n",
    "tags = soup10.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req11 = requests.get(\"https://elpais.com/babelia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup11 = BeautifulSoup(req11.text, 'html.parser')\n",
    "\n",
    "tags = soup11.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b77d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "req12 = requests.get(\"https://elpais.com/deportes/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup12 = BeautifulSoup(req12.text, 'html.parser')\n",
    "\n",
    "tags = soup12.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85caff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "req13 = requests.get(\"https://elpais.com/tecnologia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup13 = BeautifulSoup(req13.text, 'html.parser')\n",
    "\n",
    "tags = soup13.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63913c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "req15 = requests.get(\"https://elpais.com/gente/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup15 = BeautifulSoup(req15.text, 'html.parser')\n",
    "\n",
    "tags = soup15.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86159eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "req17 = requests.get(\"https://elpais.com/eps/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup17 = BeautifulSoup(req17.text, 'html.parser')\n",
    "\n",
    "tags = soup17.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb463915",
   "metadata": {},
   "source": [
    "Para limpiar la pantalla usamos **os.system(\"clear\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "193c60c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"clear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3550a1",
   "metadata": {},
   "source": [
    "Con **print(colored)** añadimos el atributo de color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73557763",
   "metadata": {},
   "source": [
    "y con **attrs** se mostrará los títulos con el estilo deseado, en este caso **bold**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5e5f4",
   "metadata": {},
   "source": [
    "### Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7194f32",
   "metadata": {},
   "source": [
    "A continuación se muestran los titulares de las páginas principales del diario El País que contienen las siguientes palabras:\n",
    "Feminismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35279b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A continuación se muestran los titulares de las páginas principales del diario El País que contienen las siguientes palabras:\n",
      "Feminismo\n"
     ]
    }
   ],
   "source": [
    "print(colored(\"A continuación se muestran los titulares de las páginas principales del diario El País que contienen las siguientes palabras:\", 'blue', attrs=['bold']))\n",
    "print(colored(\"Feminismo\", 'green', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2b010",
   "metadata": {},
   "source": [
    "se crea una variable llamada **str_match** y sé utilizando la función **for** para comprobar que tengan las palabras claves, este se repite una y otra vez "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a9a3d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Americanas: Reportajes y noticias sobre feminismo e historias con enfoque de género de la región\n",
      "El feminismo se fractura en Madrid en las protestas contra la violencia machista que recorren España\n",
      "Americanas: Reportajes y noticias sobre feminismo e historias con enfoque de género de la región\n"
     ]
    }
   ],
   "source": [
    "str_match = [s for s in resultados if \"feminismo\" in s]\n",
    "print(\"\\n\".join(str_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9176cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Igualdad\n",
      "El caso de Georgia, en EE UU: becar sin importar la renta agranda la desigualdad\n",
      "Mujeres\n",
      "Otras mujeres\n",
      "El Kremlin silencia el dolor de las mujeres rusas que critican la guerra de Ucrania \n",
      "¿Protege más a las mujeres elevar las penas?\n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "El embarazo transforma el cerebro de las mujeres para favorecer el vínculo con sus hijos\n",
      "Otras mujeres\n",
      "El primer protagonista homosexual de Disney y un ejército de mujeres capitaneada por Viola Davis, entre los estrenos de la semana\n",
      "Otras mujeres\n",
      "El Kremlin silencia el dolor de las mujeres rusas que critican la guerra de Ucrania \n",
      "Mujer\n",
      "Otras mujeres\n",
      "Confesiones de la mujer que lleva 40 años decidiendo quién será el nuevo James Bond\n",
      "El Kremlin silencia el dolor de las mujeres rusas que critican la guerra de Ucrania \n",
      "La insólita historia de la mujer que descubrió el primer antibiótico español\n",
      "“Me rompí por dentro y hasta hoy”: desgarrador testimonio de una mujer a la que nadie creyó mientras era víctima de acoso\n",
      "¿Protege más a las mujeres elevar las penas?\n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "La insólita historia de la mujer que descubrió el primer antibiótico español\n",
      "El embarazo transforma el cerebro de las mujeres para favorecer el vínculo con sus hijos\n",
      "Otras mujeres\n",
      "El primer protagonista homosexual de Disney y un ejército de mujeres capitaneada por Viola Davis, entre los estrenos de la semana\n",
      "Confesiones de la mujer que lleva 40 años decidiendo quién será James Bond\n",
      "Muchos hombres, una sola mujer\n",
      "Otras mujeres\n",
      "Confesiones de la mujer que lleva 40 años decidiendo quién será el nuevo James Bond\n",
      "El Kremlin silencia el dolor de las mujeres rusas que critican la guerra de Ucrania \n",
      "La insólita historia de la mujer que descubrió el primer antibiótico español\n",
      "“Me rompí por dentro y hasta hoy”: desgarrador testimonio de una mujer a la que nadie creyó mientras era víctima de acoso\n",
      "Brecha salarial\n",
      "\n",
      "Machismo\n",
      "\n",
      "Violencia\n",
      "Otra forma de violencia política\n",
      "La violencia verbal de Vox desborda el Congreso español\n",
      "\n",
      "Otra forma de violencia política\n",
      "Contra la violencia machista \n",
      "Otra forma de violencia política\n",
      "Abascal defiende la violencia verbal de Vox y llama “enloquecida” a la ministra Irene Montero \n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "El feminismo se fractura en Madrid en las protestas contra la violencia machista que recorren España\n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "328 mensajes de tu ex o cómo la violencia machista entra por el móvil\n",
      "La violencia machista entre los adolescentes, el drama que ni ellos quieren reconocer\n",
      "Otra forma de violencia política\n",
      "La violencia verbal de Vox desborda el Congreso español\n",
      "\n",
      "Maltrato\n",
      "¿Podré matar a una rata que entre en mi casa? Claves de la reforma del Código Penal para castigar más el maltrato animal\n",
      "¿Podré matar a una rata que entre en mi casa? Claves de la reforma del Código Penal para castigar más el maltrato animal\n",
      "¿Podré matar a una rata que entre en mi casa? Claves de la reforma del Código Penal para castigar más el maltrato animal\n",
      "Homicidio\n",
      "\n",
      "Género\n",
      "Americanas: Reportajes y noticias sobre feminismo e historias con enfoque de género de la región\n",
      "Por primera vez un juez declara nulo un contrato de alquiler por aplicación de la perspectiva de género\n",
      "Visitas a centros de acogida y muchas horas de estudio: así se forman los jueces en materia de género\n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "Para acabar con la violencia de género, necesitamos más mujeres en posiciones de poder \n",
      "Americanas: Reportajes y noticias sobre feminismo e historias con enfoque de género de la región\n",
      "Asesinato\n",
      "Crónica del asesinato de una niña en la Francia rural\n",
      "Crónica del asesinato de una niña española en la Francia rural\n",
      "Crónica del asesinato de una niña en la Francia rural\n",
      "Sexo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(colored(\"Igualdad\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"igualdad\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Mujeres\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"mujeres\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Mujer\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"mujer\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Brecha salarial\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"brecha salarial\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Machismo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"machismo\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Violencia\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"violencia\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Maltrato\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"maltrato\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Homicidio\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"homicidio\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Género\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"género\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Asesinato\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"asesinato\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Sexo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"sexo\" in s]\n",
    "print(\"\\n\".join(str_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82163c1",
   "metadata": {},
   "source": [
    "## Ejercicio ejecutado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab58b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "\n",
    "resultados = []\n",
    "\n",
    "req = requests.get(\"https://resultados.elpais.com\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "tags = soup.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req2 = requests.get(\"https://elpais.com/internacional\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup2 = BeautifulSoup(req2.text, 'html.parser')\n",
    "\n",
    "tags = soup2.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req3 = requests.get(\"https://elpais.com/opinion\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup3 = BeautifulSoup(req3.text, 'html.parser')\n",
    "\n",
    "tags = soup3.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req4 = requests.get(\"https://elpais.com/espana/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup4 = BeautifulSoup(req4.text, 'html.parser')\n",
    "\n",
    "tags = soup4.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req5 = requests.get(\"https://elpais.com/economia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup5 = BeautifulSoup(req5.text, 'html.parser')\n",
    "\n",
    "tags = soup5.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req6 = requests.get(\"https://elpais.com/sociedad/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup6 = BeautifulSoup(req6.text, 'html.parser')\n",
    "\n",
    "tags = soup6.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req7 = requests.get(\"https://elpais.com/educacion/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup7 = BeautifulSoup(req7.text, 'html.parser')\n",
    "\n",
    "tags = soup7.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req8 = requests.get(\"https://elpais.com/clima-y-medio-ambiente/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup8 = BeautifulSoup(req8.text, 'html.parser')\n",
    "\n",
    "tags = soup8.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req9 = requests.get(\"https://elpais.com/ciencia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup9 = BeautifulSoup(req9.text, 'html.parser')\n",
    "\n",
    "tags = soup9.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req10 = requests.get(\"https://elpais.com/cultura/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup10 = BeautifulSoup(req10.text, 'html.parser')\n",
    "\n",
    "tags = soup10.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req11 = requests.get(\"https://elpais.com/babelia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup11 = BeautifulSoup(req11.text, 'html.parser')\n",
    "\n",
    "tags = soup11.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req12 = requests.get(\"https://elpais.com/deportes/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup12 = BeautifulSoup(req12.text, 'html.parser')\n",
    "\n",
    "tags = soup12.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req13 = requests.get(\"https://elpais.com/tecnologia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup13 = BeautifulSoup(req13.text, 'html.parser')\n",
    "\n",
    "tags = soup13.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req14 = requests.get(\"https://elpais.com/tecnologia/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup14 = BeautifulSoup(req14.text, 'html.parser')\n",
    "\n",
    "tags = soup14.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req15 = requests.get(\"https://elpais.com/gente/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup15 = BeautifulSoup(req15.text, 'html.parser')\n",
    "\n",
    "tags = soup15.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req16 = requests.get(\"https://elpais.com/television/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup16 = BeautifulSoup(req16.text, 'html.parser')\n",
    "\n",
    "tags = soup16.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "req17 = requests.get(\"https://elpais.com/eps/\")\n",
    "# Si el estatus code no es 200 no se puede leer la página\n",
    "if (req.status_code != 200):\n",
    " raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "soup17 = BeautifulSoup(req17.text, 'html.parser')\n",
    "\n",
    "tags = soup17.findAll(\"h2\")\n",
    "\n",
    "for h2 in tags:\n",
    "    print(h2.text)\n",
    "    resultados.append(h2.text)\n",
    "\n",
    "\n",
    "os.system(\"clear\")\n",
    "\n",
    "print(colored(\"A continuación se muestran los titulares de las páginas principales del diario El País que contienen las siguientes palabras:\", 'blue', attrs=['bold']))\n",
    "print(colored(\"Feminismo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"feminismo\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Igualdad\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"igualdad\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Mujeres\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"mujeres\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Mujer\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"mujer\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Brecha salarial\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"brecha salarial\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Machismo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"machismo\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Violencia\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"violencia\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Maltrato\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"maltrato\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Homicidio\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"homicidio\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Género\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"género\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Asesinato\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"asesinato\" in s]\n",
    "print(\"\\n\".join(str_match))\n",
    "\n",
    "print(colored(\"Sexo\", 'green', attrs=['bold']))\n",
    "\n",
    "str_match = [s for s in resultados if \"sexo\" in s]\n",
    "print(\"\\n\".join(str_match))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
